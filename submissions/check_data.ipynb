{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5feb47c-c05f-442b-8009-4b7272bdf84f",
   "metadata": {},
   "source": [
    "## No external data + xgboost + cosine - 0.76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d167cd0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;functiontransformer&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function _encode_dates at 0x1204884c0&gt;)),\n",
       "                (&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;date&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;year&#x27;, &#x27;month&#x27;, &#x27;day&#x27;,\n",
       "                                                   &#x27;weekday&#x27;, &#x27;hour_sin&#x27;,\n",
       "                                                   &#x27;hour_cos&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;counter_name&#x27;,\n",
       "                                                   &#x27;site_name&#x27;])])),\n",
       "                (&#x27;xgbregress...\n",
       "                              feature_types=None, gamma=None, grow_policy=None,\n",
       "                              importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=None,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=None, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, multi_strategy=None,\n",
       "                              n_estimators=None, n_jobs=None,\n",
       "                              num_parallel_tree=None, random_state=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;functiontransformer&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function _encode_dates at 0x1204884c0&gt;)),\n",
       "                (&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;date&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;year&#x27;, &#x27;month&#x27;, &#x27;day&#x27;,\n",
       "                                                   &#x27;weekday&#x27;, &#x27;hour_sin&#x27;,\n",
       "                                                   &#x27;hour_cos&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;counter_name&#x27;,\n",
       "                                                   &#x27;site_name&#x27;])])),\n",
       "                (&#x27;xgbregress...\n",
       "                              feature_types=None, gamma=None, grow_policy=None,\n",
       "                              importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=None,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=None, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, multi_strategy=None,\n",
       "                              n_estimators=None, n_jobs=None,\n",
       "                              num_parallel_tree=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function _encode_dates at 0x1204884c0&gt;)</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;date&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;year&#x27;, &#x27;month&#x27;, &#x27;day&#x27;, &#x27;weekday&#x27;, &#x27;hour_sin&#x27;,\n",
       "                                  &#x27;hour_cos&#x27;]),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;counter_name&#x27;, &#x27;site_name&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">date</label><div class=\"sk-toggleable__content\"><pre>[&#x27;year&#x27;, &#x27;month&#x27;, &#x27;day&#x27;, &#x27;weekday&#x27;, &#x27;hour_sin&#x27;, &#x27;hour_cos&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;counter_name&#x27;, &#x27;site_name&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('functiontransformer',\n",
       "                 FunctionTransformer(func=<function _encode_dates at 0x1204884c0>)),\n",
       "                ('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('date',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['year', 'month', 'day',\n",
       "                                                   'weekday', 'hour_sin',\n",
       "                                                   'hour_cos']),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['counter_name',\n",
       "                                                   'site_name'])])),\n",
       "                ('xgbregress...\n",
       "                              feature_types=None, gamma=None, grow_policy=None,\n",
       "                              importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=None,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=None, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, multi_strategy=None,\n",
       "                              n_estimators=None, n_jobs=None,\n",
       "                              num_parallel_tree=None, random_state=None, ...))])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import FunctionTransformer, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost as xgb\n",
    "\n",
    "# Constants\n",
    "problem_title = \"Bike count prediction\"\n",
    "_target_column_name = \"log_bike_count\"\n",
    "\n",
    "# Function to read data\n",
    "def _read_data(path, f_name, is_train=True):\n",
    "    data = pd.read_parquet(os.path.join(path, \"input/msdb-2023/\", f_name))\n",
    "    data = data.sort_values([\"date\", \"counter_name\"])\n",
    "    \n",
    "    if is_train:\n",
    "        y_array = data[_target_column_name].values\n",
    "        X_df = data.drop([_target_column_name, \"bike_count\"], axis=1)\n",
    "        return X_df, y_array\n",
    "    else:\n",
    "        X_df = data\n",
    "        return X_df\n",
    "\n",
    "# Get train and test data\n",
    "def get_train_data(path=\".\"):\n",
    "    f_name = \"train.parquet\"\n",
    "    return _read_data(path, f_name, is_train=True)\n",
    "\n",
    "def get_test_data(path=\".\"):\n",
    "    f_name = \"final_test.parquet\"\n",
    "    return _read_data(path, f_name, is_train=False)\n",
    "\n",
    "# Load the train and test data\n",
    "X_train, y_train = get_train_data()\n",
    "X_test = get_test_data()\n",
    "\n",
    "# Date encoding with cyclic hour feature\n",
    "def _encode_dates(X):\n",
    "    X = X.copy()\n",
    "    X.loc[:, \"year\"] = X[\"date\"].dt.year\n",
    "    X.loc[:, \"month\"] = X[\"date\"].dt.month\n",
    "    X.loc[:, \"day\"] = X[\"date\"].dt.day\n",
    "    X.loc[:, \"weekday\"] = X[\"date\"].dt.weekday\n",
    "    X.loc[:, \"hour_sin\"] = np.sin(2 * np.pi * X[\"date\"].dt.hour/23.0)\n",
    "    X.loc[:, \"hour_cos\"] = np.cos(2 * np.pi * X[\"date\"].dt.hour/23.0)\n",
    "\n",
    "    return X.drop(columns=[\"date\"])\n",
    "\n",
    "date_encoder = FunctionTransformer(_encode_dates)\n",
    "date_cols = _encode_dates(X_train[[\"date\"]]).columns.tolist()\n",
    "\n",
    "# Preprocessing\n",
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "categorical_cols = [\"counter_name\", \"site_name\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"date\", OneHotEncoder(handle_unknown=\"ignore\"), date_cols),\n",
    "        (\"cat\", categorical_encoder, categorical_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Model\n",
    "xgb_regressor = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "pipeline = make_pipeline(date_encoder, preprocessor, xgb_regressor)\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2324639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "results_dict = {'Id': X_test.index.tolist(), 'log_bike_count': y_pred}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d8bbdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set, RMSE=0.52\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\n",
    "    f\"Train set, RMSE={mean_squared_error(y_train, pipeline.predict(X_train), squared=False):.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c84cacc",
   "metadata": {},
   "source": [
    "## Weather data + xgboost + cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f214a4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter_id</th>\n",
       "      <th>counter_name</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_name</th>\n",
       "      <th>date</th>\n",
       "      <th>counter_installation_date</th>\n",
       "      <th>counter_technical_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17081</th>\n",
       "      <td>100049407-353255860</td>\n",
       "      <td>152 boulevard du Montparnasse E-O</td>\n",
       "      <td>100049407</td>\n",
       "      <td>152 boulevard du Montparnasse</td>\n",
       "      <td>2021-09-10 01:00:00</td>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>Y2H19070373</td>\n",
       "      <td>48.840801</td>\n",
       "      <td>2.333233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18655</th>\n",
       "      <td>100049407-353255859</td>\n",
       "      <td>152 boulevard du Montparnasse O-E</td>\n",
       "      <td>100049407</td>\n",
       "      <td>152 boulevard du Montparnasse</td>\n",
       "      <td>2021-09-10 01:00:00</td>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>Y2H19070373</td>\n",
       "      <td>48.840801</td>\n",
       "      <td>2.333233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>100036719-104036719</td>\n",
       "      <td>18 quai de l'Hôtel de Ville NO-SE</td>\n",
       "      <td>100036719</td>\n",
       "      <td>18 quai de l'Hôtel de Ville</td>\n",
       "      <td>2021-09-10 01:00:00</td>\n",
       "      <td>2017-07-12</td>\n",
       "      <td>Y2H19027732</td>\n",
       "      <td>48.853720</td>\n",
       "      <td>2.357020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>100036719-103036719</td>\n",
       "      <td>18 quai de l'Hôtel de Ville SE-NO</td>\n",
       "      <td>100036719</td>\n",
       "      <td>18 quai de l'Hôtel de Ville</td>\n",
       "      <td>2021-09-10 01:00:00</td>\n",
       "      <td>2017-07-12</td>\n",
       "      <td>Y2H19027732</td>\n",
       "      <td>48.853720</td>\n",
       "      <td>2.357020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48210</th>\n",
       "      <td>100063175-353277233</td>\n",
       "      <td>20 Avenue de Clichy NO-SE</td>\n",
       "      <td>100063175</td>\n",
       "      <td>20 Avenue de Clichy</td>\n",
       "      <td>2021-09-10 01:00:00</td>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>Y2H20073268</td>\n",
       "      <td>48.885290</td>\n",
       "      <td>2.326660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                counter_id                       counter_name    site_id  \\\n",
       "17081  100049407-353255860  152 boulevard du Montparnasse E-O  100049407   \n",
       "18655  100049407-353255859  152 boulevard du Montparnasse O-E  100049407   \n",
       "3124   100036719-104036719  18 quai de l'Hôtel de Ville NO-SE  100036719   \n",
       "4147   100036719-103036719  18 quai de l'Hôtel de Ville SE-NO  100036719   \n",
       "48210  100063175-353277233          20 Avenue de Clichy NO-SE  100063175   \n",
       "\n",
       "                           site_name                date  \\\n",
       "17081  152 boulevard du Montparnasse 2021-09-10 01:00:00   \n",
       "18655  152 boulevard du Montparnasse 2021-09-10 01:00:00   \n",
       "3124     18 quai de l'Hôtel de Ville 2021-09-10 01:00:00   \n",
       "4147     18 quai de l'Hôtel de Ville 2021-09-10 01:00:00   \n",
       "48210            20 Avenue de Clichy 2021-09-10 01:00:00   \n",
       "\n",
       "      counter_installation_date counter_technical_id   latitude  longitude  \n",
       "17081                2018-12-07          Y2H19070373  48.840801   2.333233  \n",
       "18655                2018-12-07          Y2H19070373  48.840801   2.333233  \n",
       "3124                 2017-07-12          Y2H19027732  48.853720   2.357020  \n",
       "4147                 2017-07-12          Y2H19027732  48.853720   2.357020  \n",
       "48210                2020-07-22          Y2H20073268  48.885290   2.326660  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost as xgb  # Import XGBoost\n",
    "from sklearn.pipeline import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "problem_title = \"Bike count prediction\"\n",
    "_target_column_name = \"log_bike_count\"\n",
    "\n",
    "def get_cv(X, y, random_state=0):\n",
    "    cv = TimeSeriesSplit(n_splits=8)\n",
    "    rng = np.random.RandomState(random_state)\n",
    "\n",
    "    for train_idx, test_idx in cv.split(X):\n",
    "        yield train_idx, rng.choice(test_idx, size=len(test_idx) // 3, replace=False)\n",
    "\n",
    "def _read_data(path, f_name, is_train=True):\n",
    "    # Change the file reading method to use pd.read_csv for CSV files\n",
    "    data = pd.read_parquet(os.path.join(path, f_name))\n",
    "    if 'date' in data.columns:\n",
    "        data['date'] = pd.to_datetime(data['date'])\n",
    "    data = data.sort_values([\"date\", \"counter_name\"])\n",
    "    \n",
    "    if is_train:\n",
    "        y_array = data[_target_column_name].values\n",
    "        X_df = data.drop([_target_column_name, \"bike_count\"], axis=1)\n",
    "        return X_df, y_array\n",
    "    else:\n",
    "        X_df = data\n",
    "        return X_df\n",
    "\n",
    "\n",
    "def get_train_data(path=\".\"):\n",
    "    f_name = \"train.parquet\" \n",
    "    return _read_data(path, f_name, is_train=True)\n",
    "\n",
    "def get_test_data(path=\".\"):\n",
    "    f_name = \"final_test.parquet\" \n",
    "    return _read_data(path, f_name, is_train=False)\n",
    "\n",
    "# Loading the train and test data\n",
    "X_train, y_train = get_train_data()\n",
    "X_test = get_test_data()\n",
    "X_test = X_test.drop(columns=['coordinates'])\n",
    "X_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f380461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encode_dates(X):\n",
    "    X = X.copy()\n",
    "    #X.loc[:, \"year\"] = X[\"date\"].dt.year\n",
    "    X.loc[:, \"month_sin\"] = np.sin(2 * np.pi * X[\"date\"].dt.month / 12.0)\n",
    "    X.loc[:, \"month_cos\"] = np.cos(2 * np.pi * X[\"date\"].dt.month / 12.0)\n",
    "    #X.loc[:, \"day\"] = X[\"date\"].dt.day\n",
    "    X.loc[:, \"weekday\"] = X[\"date\"].dt.weekday\n",
    "    X.loc[:, \"hour_sin\"] = np.sin(2 * np.pi * X[\"date\"].dt.hour/23.0)\n",
    "    X.loc[:, \"hour_cos\"] = np.cos(2 * np.pi * X[\"date\"].dt.hour/23.0)\n",
    "\n",
    "    # weekend encoding\n",
    "    X.loc[:, \"is_weekend\"] = (X[\"date\"].dt.weekday >= 5).astype(int)\n",
    "\n",
    "\n",
    "    return X.drop(columns=[\"date\"])\n",
    "\n",
    "def _merge_external_data(X):\n",
    "    file_path = \"hourly-weather-data.csv\"  \n",
    "    df_ext = pd.read_csv(file_path, parse_dates=[\"date\"])\n",
    "\n",
    "    # Remove rows with null 'date' in the external data\n",
    "    X['date'] = X['date'].astype('datetime64[ns]')\n",
    "    df_ext['date'] = df_ext['date'].astype('datetime64[ns]')\n",
    "    df_ext = df_ext.dropna(subset=['date'])\n",
    "\n",
    "    X = X.copy()\n",
    "    X[\"orig_index\"] = np.arange(X.shape[0])\n",
    "    X = pd.merge_asof(X.sort_values(\"date\"), df_ext.sort_values(\"date\"), on=\"date\")\n",
    "    X = X.sort_values(\"orig_index\")\n",
    "    del X[\"orig_index\"]\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60d42b83",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing column provided to 'parse_dates': 'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/elisebarattini/Documents/1_UNIVERSITY/1.3_Masters/DSB/Courses/1_Semester/Python_DS/Project/project_bike/check_data.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/elisebarattini/Documents/1_UNIVERSITY/1.3_Masters/DSB/Courses/1_Semester/Python_DS/Project/project_bike/check_data.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m regressor \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBRegressor(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, min_child_weight\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m,n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)  \u001b[39m# Use XGBRegressor with objective\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/elisebarattini/Documents/1_UNIVERSITY/1.3_Masters/DSB/Courses/1_Semester/Python_DS/Project/project_bike/check_data.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m pipeline \u001b[39m=\u001b[39m Pipeline(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/elisebarattini/Documents/1_UNIVERSITY/1.3_Masters/DSB/Courses/1_Semester/Python_DS/Project/project_bike/check_data.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     steps\u001b[39m=\u001b[39m[\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/elisebarattini/Documents/1_UNIVERSITY/1.3_Masters/DSB/Courses/1_Semester/Python_DS/Project/project_bike/check_data.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         (\u001b[39m'\u001b[39m\u001b[39mmerge external data\u001b[39m\u001b[39m'\u001b[39m, data_merger),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/elisebarattini/Documents/1_UNIVERSITY/1.3_Masters/DSB/Courses/1_Semester/Python_DS/Project/project_bike/check_data.ipynb#X10sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/elisebarattini/Documents/1_UNIVERSITY/1.3_Masters/DSB/Courses/1_Semester/Python_DS/Project/project_bike/check_data.ipynb#X10sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/elisebarattini/Documents/1_UNIVERSITY/1.3_Masters/DSB/Courses/1_Semester/Python_DS/Project/project_bike/check_data.ipynb#X10sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m pipeline\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/pipeline.py:423\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \n\u001b[1;32m    399\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    422\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 423\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    424\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[1;32m    425\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/pipeline.py:377\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    375\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[1;32m    376\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    378\u001b[0m     cloned_transformer,\n\u001b[1;32m    379\u001b[0m     X,\n\u001b[1;32m    380\u001b[0m     y,\n\u001b[1;32m    381\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    382\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    383\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    384\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[1;32m    385\u001b[0m )\n\u001b[1;32m    386\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 353\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/pipeline.py:957\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    956\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 957\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    958\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    959\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:919\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    917\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    918\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 919\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/preprocessing/_function_transformer.py:240\u001b[0m, in \u001b[0;36mFunctionTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Transform X using the forward function.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \n\u001b[1;32m    228\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39m    Transformed input.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_input(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 240\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(X, func\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc, kw_args\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkw_args)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/preprocessing/_function_transformer.py:312\u001b[0m, in \u001b[0;36mFunctionTransformer._transform\u001b[0;34m(self, X, func, kw_args)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[39mif\u001b[39;00m func \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    310\u001b[0m     func \u001b[39m=\u001b[39m _identity\n\u001b[0;32m--> 312\u001b[0m \u001b[39mreturn\u001b[39;00m func(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m(kw_args \u001b[39mif\u001b[39;49;00m kw_args \u001b[39melse\u001b[39;49;00m {}))\n",
      "\u001b[1;32m/Users/elisebarattini/Documents/1_UNIVERSITY/1.3_Masters/DSB/Courses/1_Semester/Python_DS/Project/project_bike/check_data.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/elisebarattini/Documents/1_UNIVERSITY/1.3_Masters/DSB/Courses/1_Semester/Python_DS/Project/project_bike/check_data.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_merge_external_data\u001b[39m(X):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/elisebarattini/Documents/1_UNIVERSITY/1.3_Masters/DSB/Courses/1_Semester/Python_DS/Project/project_bike/check_data.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     file_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhourly-weather-data.csv\u001b[39m\u001b[39m\"\u001b[39m  \n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/elisebarattini/Documents/1_UNIVERSITY/1.3_Masters/DSB/Courses/1_Semester/Python_DS/Project/project_bike/check_data.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     df_ext \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(file_path, parse_dates\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/elisebarattini/Documents/1_UNIVERSITY/1.3_Masters/DSB/Courses/1_Semester/Python_DS/Project/project_bike/check_data.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m# Remove rows with null 'date' in the external data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/elisebarattini/Documents/1_UNIVERSITY/1.3_Masters/DSB/Courses/1_Semester/Python_DS/Project/project_bike/check_data.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     X[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m X[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mdatetime64[ns]\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1723\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1720\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1722\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1723\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[1;32m   1724\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1725\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:161\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_usecols_names(\n\u001b[1;32m    156\u001b[0m             usecols,\n\u001b[1;32m    157\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames,  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    158\u001b[0m         )\n\u001b[1;32m    160\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_parse_dates_presence(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnames)  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_noconvert_columns()\n\u001b[1;32m    164\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/base_parser.py:242\u001b[0m, in \u001b[0;36mParserBase._validate_parse_dates_presence\u001b[0;34m(self, columns)\u001b[0m\n\u001b[1;32m    232\u001b[0m missing_cols \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m    233\u001b[0m     \u001b[39msorted\u001b[39m(\n\u001b[1;32m    234\u001b[0m         {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m     )\n\u001b[1;32m    240\u001b[0m )\n\u001b[1;32m    241\u001b[0m \u001b[39mif\u001b[39;00m missing_cols:\n\u001b[0;32m--> 242\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    243\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing column provided to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mparse_dates\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmissing_cols\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m     )\n\u001b[1;32m    245\u001b[0m \u001b[39m# Convert positions to actual column names\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    247\u001b[0m     col \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39m(col, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m col \u001b[39min\u001b[39;00m columns) \u001b[39melse\u001b[39;00m columns[col]\n\u001b[1;32m    248\u001b[0m     \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m cols_needed\n\u001b[1;32m    249\u001b[0m ]\n",
      "\u001b[0;31mValueError\u001b[0m: Missing column provided to 'parse_dates': 'date'"
     ]
    }
   ],
   "source": [
    "date_encoder = FunctionTransformer(_encode_dates)\n",
    "date_cols = _encode_dates(X_train[[\"date\"]]).columns.tolist()\n",
    "\n",
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "categorical_cols = [\"counter_name\", \"site_name\"]\n",
    "\n",
    "numerical_cols = ['feelslike']\n",
    "\n",
    "data_merger = FunctionTransformer(_merge_external_data, validate=False)\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"date\", OneHotEncoder(handle_unknown=\"ignore\"), date_cols),\n",
    "        (\"cat\", categorical_encoder, categorical_cols),\n",
    "        (\"standard scaler\", StandardScaler(), numerical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "regressor = xgb.XGBRegressor(learning_rate=0.1, max_depth=10, min_child_weight=12,n_estimators=100)  # Use XGBRegressor with objective\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('merge external data', data_merger),\n",
    "        ('date encoder', date_encoder),\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor',regressor)\n",
    "    ]\n",
    ")\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90c7a788",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "results_dict = {'Id': X_test.index.tolist(), 'log_bike_count': y_pred}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f64e4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set, RMSE=0.54\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\n",
    "    f\"Train set, RMSE={mean_squared_error(y_train, pipeline.predict(X_train), squared=False):.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d3444d",
   "metadata": {},
   "source": [
    "## All external Data + xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3fb6dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter_id</th>\n",
       "      <th>counter_name</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_name</th>\n",
       "      <th>date</th>\n",
       "      <th>counter_installation_date</th>\n",
       "      <th>counter_technical_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17081</th>\n",
       "      <td>100049407-353255860</td>\n",
       "      <td>152 boulevard du Montparnasse E-O</td>\n",
       "      <td>100049407</td>\n",
       "      <td>152 boulevard du Montparnasse</td>\n",
       "      <td>2021-09-10 01:00:00</td>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>Y2H19070373</td>\n",
       "      <td>48.840801</td>\n",
       "      <td>2.333233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18655</th>\n",
       "      <td>100049407-353255859</td>\n",
       "      <td>152 boulevard du Montparnasse O-E</td>\n",
       "      <td>100049407</td>\n",
       "      <td>152 boulevard du Montparnasse</td>\n",
       "      <td>2021-09-10 01:00:00</td>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>Y2H19070373</td>\n",
       "      <td>48.840801</td>\n",
       "      <td>2.333233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>100036719-104036719</td>\n",
       "      <td>18 quai de l'Hôtel de Ville NO-SE</td>\n",
       "      <td>100036719</td>\n",
       "      <td>18 quai de l'Hôtel de Ville</td>\n",
       "      <td>2021-09-10 01:00:00</td>\n",
       "      <td>2017-07-12</td>\n",
       "      <td>Y2H19027732</td>\n",
       "      <td>48.853720</td>\n",
       "      <td>2.357020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>100036719-103036719</td>\n",
       "      <td>18 quai de l'Hôtel de Ville SE-NO</td>\n",
       "      <td>100036719</td>\n",
       "      <td>18 quai de l'Hôtel de Ville</td>\n",
       "      <td>2021-09-10 01:00:00</td>\n",
       "      <td>2017-07-12</td>\n",
       "      <td>Y2H19027732</td>\n",
       "      <td>48.853720</td>\n",
       "      <td>2.357020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48210</th>\n",
       "      <td>100063175-353277233</td>\n",
       "      <td>20 Avenue de Clichy NO-SE</td>\n",
       "      <td>100063175</td>\n",
       "      <td>20 Avenue de Clichy</td>\n",
       "      <td>2021-09-10 01:00:00</td>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>Y2H20073268</td>\n",
       "      <td>48.885290</td>\n",
       "      <td>2.326660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                counter_id                       counter_name    site_id  \\\n",
       "17081  100049407-353255860  152 boulevard du Montparnasse E-O  100049407   \n",
       "18655  100049407-353255859  152 boulevard du Montparnasse O-E  100049407   \n",
       "3124   100036719-104036719  18 quai de l'Hôtel de Ville NO-SE  100036719   \n",
       "4147   100036719-103036719  18 quai de l'Hôtel de Ville SE-NO  100036719   \n",
       "48210  100063175-353277233          20 Avenue de Clichy NO-SE  100063175   \n",
       "\n",
       "                           site_name                date  \\\n",
       "17081  152 boulevard du Montparnasse 2021-09-10 01:00:00   \n",
       "18655  152 boulevard du Montparnasse 2021-09-10 01:00:00   \n",
       "3124     18 quai de l'Hôtel de Ville 2021-09-10 01:00:00   \n",
       "4147     18 quai de l'Hôtel de Ville 2021-09-10 01:00:00   \n",
       "48210            20 Avenue de Clichy 2021-09-10 01:00:00   \n",
       "\n",
       "      counter_installation_date counter_technical_id   latitude  longitude  \n",
       "17081                2018-12-07          Y2H19070373  48.840801   2.333233  \n",
       "18655                2018-12-07          Y2H19070373  48.840801   2.333233  \n",
       "3124                 2017-07-12          Y2H19027732  48.853720   2.357020  \n",
       "4147                 2017-07-12          Y2H19027732  48.853720   2.357020  \n",
       "48210                2020-07-22          Y2H20073268  48.885290   2.326660  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "problem_title = \"Bike count prediction\"\n",
    "_target_column_name = \"log_bike_count\"\n",
    "\n",
    "def get_cv(X, y, random_state=0):\n",
    "    cv = TimeSeriesSplit(n_splits=8)\n",
    "    rng = np.random.RandomState(random_state)\n",
    "\n",
    "    for train_idx, test_idx in cv.split(X):\n",
    "        yield train_idx, rng.choice(test_idx, size=len(test_idx) // 3, replace=False)\n",
    "\n",
    "def _read_data(path, f_name, is_train=True):\n",
    "    # Change the file reading method to use pd.read_csv for CSV files\n",
    "    data = pd.read_parquet(os.path.join(path, f_name))\n",
    "    if 'date' in data.columns:\n",
    "        data['date'] = pd.to_datetime(data['date'])\n",
    "    data = data.sort_values([\"date\", \"counter_name\"])\n",
    "    \n",
    "    if is_train:\n",
    "        y_array = data[_target_column_name].values\n",
    "        X_df = data.drop([_target_column_name, \"bike_count\"], axis=1)\n",
    "        return X_df, y_array\n",
    "    else:\n",
    "        X_df = data\n",
    "        return X_df\n",
    "\n",
    "\n",
    "def get_train_data(path=\".\"):\n",
    "    f_name = \"train.parquet\" \n",
    "    return _read_data(path, f_name, is_train=True)\n",
    "\n",
    "def get_test_data(path=\".\"):\n",
    "    f_name = \"final_test.parquet\" \n",
    "    return _read_data(path, f_name, is_train=False)\n",
    "\n",
    "# Loading the train and test data\n",
    "X_train, y_train = get_train_data()\n",
    "X_test = get_test_data()\n",
    "X_test = X_test.drop(columns=['coordinates'])\n",
    "X_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69daf252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encode_dates(X):\n",
    "    X = X.copy()\n",
    "    X.loc[:, \"year\"] = X[\"date\"].dt.year\n",
    "    X.loc[:, \"day\"] = X[\"date\"].dt.day\n",
    "    X.loc[:, \"weekday\"] = X[\"date\"].dt.weekday\n",
    "\n",
    "    # weekend encoding\n",
    "    X.loc[:, \"is_weekend\"] = (X[\"date\"].dt.weekday >= 5).astype(int)\n",
    "\n",
    "    # cosine encodings to capture cyclical patterns\n",
    "    # months\n",
    "    X.loc[:, \"month_sin\"] = np.sin(2 * np.pi * X[\"date\"].dt.month / 12.0)\n",
    "    X.loc[:, \"month_cos\"] = np.cos(2 * np.pi * X[\"date\"].dt.month / 12.0)\n",
    "    # hours\n",
    "    X.loc[:, \"hour_sin\"] = np.sin(2 * np.pi * X[\"date\"].dt.hour / 23.0)\n",
    "    X.loc[:, \"hour_cos\"] = np.cos(2 * np.pi * X[\"date\"].dt.hour / 23.0)\n",
    "\n",
    "    # Rush hour for weekdays (Monday=0, Sunday=6)\n",
    "    X.loc[:, \"morning_rush\"] = ((X[\"weekday\"] < 5) & (X[\"date\"].dt.hour >= 7) & (X[\"date\"].dt.hour <= 9)).astype(int)\n",
    "    X.loc[:, \"evening_rush\"] = ((X[\"weekday\"] < 5) & (X[\"date\"].dt.hour >= 16) & (X[\"date\"].dt.hour <= 18)).astype(int)\n",
    "    \n",
    "    return X.drop(columns=[\"date\"])\n",
    "\n",
    "\n",
    "\n",
    "def _merge_external_data(X):\n",
    "    file_path = \"all-ext-data.csv\"\n",
    "    df_ext = pd.read_csv(file_path, parse_dates=[\"date\"])\n",
    "\n",
    "    # Remove rows with null 'date' in the external data\n",
    "    X['date'] = X['date'].astype('datetime64[ns]')\n",
    "    df_ext['date'] = df_ext['date'].astype('datetime64[ns]')\n",
    "    df_ext = df_ext.dropna(subset=['date'])\n",
    "\n",
    "    X = X.copy()\n",
    "    X[\"orig_index\"] = np.arange(X.shape[0])\n",
    "    X = pd.merge_asof(X.sort_values(\"date\"), df_ext.sort_values(\"date\"), on=\"date\")\n",
    "    X = X.sort_values(\"orig_index\")\n",
    "    del X[\"orig_index\"]\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e710d324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>feelslike</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precip</th>\n",
       "      <th>conditions</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>full_lockdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-19 19:00:00</td>\n",
       "      <td>23.8</td>\n",
       "      <td>52.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-09-19 19:00:00</td>\n",
       "      <td>23.8</td>\n",
       "      <td>52.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-19 19:00:00</td>\n",
       "      <td>23.8</td>\n",
       "      <td>52.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-09-19 19:00:00</td>\n",
       "      <td>23.8</td>\n",
       "      <td>52.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-09-19 19:00:00</td>\n",
       "      <td>23.8</td>\n",
       "      <td>52.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  feelslike  humidity  precip conditions  is_holiday  \\\n",
       "0 2020-09-19 19:00:00       23.8     52.82     0.0   Overcast           0   \n",
       "1 2020-09-19 19:00:00       23.8     52.82     0.0   Overcast           0   \n",
       "2 2020-09-19 19:00:00       23.8     52.82     0.0   Overcast           0   \n",
       "3 2020-09-19 19:00:00       23.8     52.82     0.0   Overcast           0   \n",
       "4 2020-09-19 19:00:00       23.8     52.82     0.0   Overcast           0   \n",
       "\n",
       "   full_lockdown  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_data = pd.read_csv(\"all-ext-data.csv\", parse_dates=[\"date\"])\n",
    "ext_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a1fb439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;merge external data&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function _merge_external_data at 0x128c71900&gt;)),\n",
       "                (&#x27;date encoder&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function _encode_dates at 0x10c346320&gt;)),\n",
       "                (&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;date&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;year&#x27;, &#x27;day&#x27;, &#x27;weekday&#x27;,\n",
       "                                                   &#x27;is_weekend&#x27;, &#x27;month_sin&#x27;,\n",
       "                                                   &#x27;month_cos&#x27;, &#x27;hour_s...\n",
       "                              feature_types=None, gamma=None, grow_policy=None,\n",
       "                              importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=0.5,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=8, max_leaves=None, min_child_weight=16,\n",
       "                              missing=nan, monotone_constraints=None,\n",
       "                              multi_strategy=None, n_estimators=100, n_jobs=1,\n",
       "                              num_parallel_tree=None, random_state=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;merge external data&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function _merge_external_data at 0x128c71900&gt;)),\n",
       "                (&#x27;date encoder&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function _encode_dates at 0x10c346320&gt;)),\n",
       "                (&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;date&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;year&#x27;, &#x27;day&#x27;, &#x27;weekday&#x27;,\n",
       "                                                   &#x27;is_weekend&#x27;, &#x27;month_sin&#x27;,\n",
       "                                                   &#x27;month_cos&#x27;, &#x27;hour_s...\n",
       "                              feature_types=None, gamma=None, grow_policy=None,\n",
       "                              importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=0.5,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=8, max_leaves=None, min_child_weight=16,\n",
       "                              missing=nan, monotone_constraints=None,\n",
       "                              multi_strategy=None, n_estimators=100, n_jobs=1,\n",
       "                              num_parallel_tree=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function _merge_external_data at 0x128c71900&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function _encode_dates at 0x10c346320&gt;)</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;date&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;year&#x27;, &#x27;day&#x27;, &#x27;weekday&#x27;, &#x27;is_weekend&#x27;,\n",
       "                                  &#x27;month_sin&#x27;, &#x27;month_cos&#x27;, &#x27;hour_sin&#x27;,\n",
       "                                  &#x27;hour_cos&#x27;, &#x27;morning_rush&#x27;, &#x27;evening_rush&#x27;]),\n",
       "                                (&#x27;categories&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;counter_name&#x27;, &#x27;site_name&#x27;, &#x27;is_holiday&#x27;]),\n",
       "                                (&#x27;standard scaler&#x27;, StandardScaler(),\n",
       "                                 [&#x27;feelslike&#x27;, &#x27;precip&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">date</label><div class=\"sk-toggleable__content\"><pre>[&#x27;year&#x27;, &#x27;day&#x27;, &#x27;weekday&#x27;, &#x27;is_weekend&#x27;, &#x27;month_sin&#x27;, &#x27;month_cos&#x27;, &#x27;hour_sin&#x27;, &#x27;hour_cos&#x27;, &#x27;morning_rush&#x27;, &#x27;evening_rush&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categories</label><div class=\"sk-toggleable__content\"><pre>[&#x27;counter_name&#x27;, &#x27;site_name&#x27;, &#x27;is_holiday&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">standard scaler</label><div class=\"sk-toggleable__content\"><pre>[&#x27;feelslike&#x27;, &#x27;precip&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.5, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "             min_child_weight=16, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=100, n_jobs=1,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('merge external data',\n",
       "                 FunctionTransformer(func=<function _merge_external_data at 0x128c71900>)),\n",
       "                ('date encoder',\n",
       "                 FunctionTransformer(func=<function _encode_dates at 0x10c346320>)),\n",
       "                ('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('date',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['year', 'day', 'weekday',\n",
       "                                                   'is_weekend', 'month_sin',\n",
       "                                                   'month_cos', 'hour_s...\n",
       "                              feature_types=None, gamma=None, grow_policy=None,\n",
       "                              importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=0.5,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=8, max_leaves=None, min_child_weight=16,\n",
       "                              missing=nan, monotone_constraints=None,\n",
       "                              multi_strategy=None, n_estimators=100, n_jobs=1,\n",
       "                              num_parallel_tree=None, random_state=None, ...))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the datasets\n",
    "date_encoder = FunctionTransformer(_encode_dates, validate=False)\n",
    "data_merger = FunctionTransformer(_merge_external_data, validate=False)\n",
    "\n",
    "# date columns\n",
    "date_cols = _encode_dates(X_train[[\"date\"]]).columns.tolist()\n",
    "\n",
    "# categorical columns\n",
    "categorical_cols = ['counter_name', 'site_name', 'is_holiday']\n",
    "\n",
    "# numerical columns\n",
    "numerical_cols = ['feelslike', 'precip']\n",
    "\n",
    "# preprocess these features\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"date\", OneHotEncoder(handle_unknown=\"ignore\"), date_cols),\n",
    "        (\"categories\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "        (\"standard scaler\", StandardScaler(), numerical_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "regressor = xgb.XGBRegressor(learning_rate=0.5, max_depth=8, min_child_weight=16, n_estimators=100, n_jobs=1, objective=\"reg:squarederror\", subsample=0.7500000000000001, verbosity=0)\n",
    "#regressor = LGBMRegressor(learning_rate=0.5, max_depth=8, n_estimators=100)\n",
    "\n",
    "\n",
    "# define the pipeline\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('merge external data', data_merger),\n",
    "        ('date encoder', date_encoder),\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', regressor)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# fit the training data\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1dc333a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set, RMSE=0.39\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\n",
    "    f\"Train set, RMSE={mean_squared_error(y_train, pipeline.predict(X_train), squared=False):.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c7452cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "results_dict = {'Id': X_test.index.tolist(), 'log_bike_count': y_pred}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
