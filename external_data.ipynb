{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a23590b",
   "metadata": {},
   "source": [
    "# MAP 536 - Python for Data Science - Predicting Cyclist Traffic in Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "97d9a34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "bd3b93a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bike_count</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>log_bike_count</th>\n",
       "      <th>temp</th>\n",
       "      <th>feelslike</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precip</th>\n",
       "      <th>snow</th>\n",
       "      <th>snowdepth</th>\n",
       "      <th>...</th>\n",
       "      <th>is_school_holiday</th>\n",
       "      <th>is_strike</th>\n",
       "      <th>full_lockdown</th>\n",
       "      <th>partial_lockdown</th>\n",
       "      <th>school_closures</th>\n",
       "      <th>business_closures</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>48.846028</td>\n",
       "      <td>2.375429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>77.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>48.846028</td>\n",
       "      <td>2.375429</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>13.3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>77.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>48.834360</td>\n",
       "      <td>2.377000</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>13.3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>77.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>48.834360</td>\n",
       "      <td>2.377000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>13.3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>77.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>48.853720</td>\n",
       "      <td>2.357020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>77.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bike_count   latitude  longitude  log_bike_count  temp  feelslike  \\\n",
       "0         0.0  48.846028   2.375429        0.000000  13.3       13.3   \n",
       "1         2.0  48.846028   2.375429        1.098612  13.3       13.3   \n",
       "2         5.0  48.834360   2.377000        1.791759  13.3       13.3   \n",
       "3         1.0  48.834360   2.377000        0.693147  13.3       13.3   \n",
       "4         0.0  48.853720   2.357020        0.000000  13.3       13.3   \n",
       "\n",
       "   humidity  precip  snow  snowdepth  ...  is_school_holiday  is_strike  \\\n",
       "0     77.67     0.0   0.0        0.0  ...                  0          0   \n",
       "1     77.67     0.0   0.0        0.0  ...                  0          0   \n",
       "2     77.67     0.0   0.0        0.0  ...                  0          0   \n",
       "3     77.67     0.0   0.0        0.0  ...                  0          0   \n",
       "4     77.67     0.0   0.0        0.0  ...                  0          0   \n",
       "\n",
       "   full_lockdown  partial_lockdown  school_closures  business_closures  year  \\\n",
       "0              0                 0                0                  0  2020   \n",
       "1              0                 0                0                  0  2020   \n",
       "2              0                 0                0                  0  2020   \n",
       "3              0                 0                0                  0  2020   \n",
       "4              0                 0                0                  0  2020   \n",
       "\n",
       "   month  day  weekday  \n",
       "0      9    1        1  \n",
       "1      9    1        1  \n",
       "2      9    1        1  \n",
       "3      9    1        1  \n",
       "4      9    1        1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## + Weather data\n",
    "# Load training and testing datasets & remove unnecessary cols\n",
    "train_data = pd.read_parquet(Path(\"data\") / \"train.parquet\")\n",
    "test_data = pd.read_parquet(Path(\"data\") / \"test.parquet\")\n",
    "train_data.drop(columns=['counter_name', 'site_name','counter_id', 'counter_installation_date', 'counter_technical_id', 'site_id'], inplace=True)\n",
    "test_data.drop(columns=['counter_name', 'site_name','counter_id', 'counter_installation_date', 'counter_technical_id', 'site_id'], inplace=True)\n",
    "\n",
    "#Load weather dataset and remove irrelevant columns\n",
    "weather_data = pd.read_csv(Path(\"data\") / \"hourly-weather-data.csv\")\n",
    "weather_data = weather_data.drop(columns=['name', 'dew', 'precipprob', 'preciptype','uvindex','icon','stations', 'sealevelpressure', 'winddir', 'conditions', 'sealevelpressure', 'severerisk', 'solarradiation', 'solarenergy'])\n",
    "\n",
    "# convert to datetime to merge them properly\n",
    "train_data['date'] = pd.to_datetime(train_data['date'])\n",
    "test_data['date'] = pd.to_datetime(test_data['date'])\n",
    "weather_data['datetime'] = pd.to_datetime(weather_data['datetime'])\n",
    "\n",
    "#merge with weather data\n",
    "merged_train_data = pd.merge(train_data, weather_data, left_on='date', right_on='datetime', how='inner')\n",
    "merged_test_data = pd.merge(test_data, weather_data, left_on='date', right_on='datetime', how='inner')\n",
    "merged_train_data = merged_train_data.drop(columns=['datetime'])\n",
    "merged_test_data = merged_test_data.drop(columns=['datetime'])\n",
    "\n",
    "\n",
    "## School Holidays + Weather data\n",
    "# import the holiday dataset\n",
    "schoolholiday_data = pd.read_csv(\"data/fr-calendrier.csv\", delimiter=';')\n",
    "schoolholiday_data = schoolholiday_data[schoolholiday_data['zones'] == 'Zone C'] # Zone C is Paris\n",
    "schoolholiday_data = schoolholiday_data.drop(columns=['description','location','annee_scolaire', 'zones'])\n",
    "\n",
    "# Convert the date strings to datetime objects\n",
    "schoolholiday_data['start_date'] = pd.to_datetime(schoolholiday_data['start_date'], utc=True).dt.date\n",
    "schoolholiday_data['end_date'] = pd.to_datetime(schoolholiday_data['end_date'],utc=True).dt.date\n",
    "\n",
    "# Generate a set of unique dates for each range in a row\n",
    "unique_dates = set()\n",
    "for _, row in schoolholiday_data.iterrows():\n",
    "    unique_dates.update(pd.date_range(start=row['start_date'], end=row['end_date']))\n",
    "\n",
    "# Convert the set back to a list and create a DataFrame\n",
    "unique_dates_list = sorted(list(unique_dates)) \n",
    "schoolholiday_data = pd.DataFrame({'Date': unique_dates_list})\n",
    "\n",
    "# merge with rest of the data\n",
    "merged_train = pd.merge(merged_train_data, schoolholiday_data, left_on='date', right_on='Date', how='left')\n",
    "merged_train['Date'] = merged_train['Date'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "merged_train.rename(columns={'Date': 'is_school_holiday'}, inplace=True)\n",
    "\n",
    "merged_test = pd.merge(merged_test_data, schoolholiday_data, left_on='date', right_on='Date', how='left')\n",
    "merged_test['Date'] = merged_test['Date'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "merged_test.rename(columns={'Date': 'is_school_holiday'}, inplace=True)\n",
    "\n",
    "\n",
    "## School Holidays + Weather data + strike data\n",
    "# import the strike dataset\n",
    "from datetime import datetime  # Import the datetime class from the datetime module\n",
    "\n",
    "# strike dates for public transport in Paris, retrieved from: https://www.cestlagreve.fr/calendrier/?lieu=74&secteur=14&mois=1&annee=2022\n",
    "strike_dates = {'Date': [datetime(2020, 9, 17), datetime(2020, 12, 14), datetime(2020, 12, 16),\n",
    "                        datetime(2021, 1, 21), datetime(2021, 2, 4), datetime(2021, 2, 15),\n",
    "                        datetime(2021, 5, 21), datetime(2021, 6, 1), datetime(2021, 10, 5),\n",
    "                        datetime(2021, 11, 17)]}\n",
    "\n",
    "strike_data = pd.DataFrame(strike_dates)\n",
    "strike_data\n",
    "\n",
    "# Convert the date strings to datetime objects\n",
    "strike_data['Date'] = pd.to_datetime(strike_data['Date'])\n",
    "\n",
    "\n",
    "# merge with rest of the data\n",
    "merged_train = pd.merge(merged_train, strike_data, left_on='date', right_on='Date', how='left')\n",
    "merged_train['Date'] = merged_train['Date'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "merged_train.rename(columns={'Date': 'is_strike'}, inplace=True)\n",
    "\n",
    "merged_test = pd.merge(merged_test, strike_data, left_on='date', right_on='Date', how='left')\n",
    "merged_test['Date'] = merged_test['Date'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "merged_test.rename(columns={'Date': 'is_strike'}, inplace=True)\n",
    "merged_test.head()\n",
    "\n",
    "\n",
    "## School Holidays + Weather data + Strike data + Lockdown data\n",
    "lockdown_data = pd.read_csv(\"data/lockdown-data.csv\")\n",
    "lockdown_data['datetime'] = pd.to_datetime(lockdown_data['datetime'])\n",
    "merged_train['date'] = pd.to_datetime(merged_train['date'])\n",
    "merged_test['date'] = pd.to_datetime(merged_test['date'])\n",
    "\n",
    "merged_train = pd.merge(merged_train, lockdown_data, left_on='date', right_on='datetime', how='left')\n",
    "merged_train = merged_train.drop(columns=['datetime'])\n",
    "merged_test = pd.merge(merged_test, lockdown_data, left_on='date', right_on='datetime', how='left')\n",
    "merged_test = merged_test.drop(columns=['datetime'])\n",
    "\n",
    "\n",
    "## Encode the dates\n",
    "def _encode_dates(X):\n",
    "    X = X.copy()  # modify a copy of X\n",
    "    X['date'] = pd.to_datetime(X['date'])\n",
    "    X.loc[:, \"year\"] = X[\"date\"].dt.year\n",
    "    X.loc[:, \"month\"] = X[\"date\"].dt.month\n",
    "    X.loc[:, \"day\"] = X[\"date\"].dt.day\n",
    "    X.loc[:, \"weekday\"] = X[\"date\"].dt.weekday\n",
    "    return X.drop(columns=[\"date\"])\n",
    "\n",
    "merged_train = _encode_dates(merged_train)\n",
    "merged_test = _encode_dates(merged_test)\n",
    "\n",
    "# define x and y\n",
    "X_merged_train = merged_train.drop(columns=['bike_count', 'log_bike_count'])\n",
    "Y_merged_train = merged_train['log_bike_count']\n",
    "\n",
    "X_merged_test = merged_test.drop(columns=['bike_count', 'log_bike_count'])\n",
    "Y_merged_test = merged_test['log_bike_count']\n",
    "\n",
    "merged_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff15d60d",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c5038f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE scores for each fold: [1.55264726 1.55290018 1.55622781 1.55799723 1.56364461]\n",
      "Average RMSE: 1.5566834174322433\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Scale the data\n",
    "    ('regressor', LinearRegression())  # Apply linear regression\n",
    "])\n",
    "\n",
    "X_merged_train = X_merged_train.fillna(X_merged_train.mean())\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Create a KFold object with shuffling\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Use this in cross_val_score\n",
    "scores = cross_val_score(pipeline, X_merged_train, Y_merged_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate RMSE for each fold\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\"RMSE scores for each fold:\", rmse_scores)\n",
    "print(\"Average RMSE:\", np.mean(rmse_scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3064b12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) for XGBoost on Cross-Validation Set: 1.31\n"
     ]
    }
   ],
   "source": [
    "# Define the target variable 'y'\n",
    "y = merged_train['log_bike_count'].copy()\n",
    "\n",
    "# Drop the target variable and any other non-predictor columns to define the features 'X'\n",
    "X = merged_train.drop(['log_bike_count', 'bike_count'], axis=1)  # Assuming 'bike_count' is also not a predictor\n",
    "\n",
    "# Calculate the split index\n",
    "split_index = int(len(X) * 0.7)\n",
    "\n",
    "# Split the features and the target variable into training and cross-validation sets\n",
    "X_train = X.iloc[:split_index]\n",
    "X_cross_val = X.iloc[split_index:]\n",
    "y_train = y.iloc[:split_index]\n",
    "y_cross_val = y.iloc[split_index:]\n",
    "\n",
    "# Your data is now split into training and cross-validation sets and is ready for model training and evaluation.\n",
    "\n",
    "num_timesteps = 24\n",
    "\n",
    "# Standardize your features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_cross_val_scaled = scaler.transform(X_cross_val)\n",
    "\n",
    "# Function to create sequences of time steps\n",
    "def create_sequences(data, y, time_steps=num_timesteps):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        v = data.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# Reshape the training and cross-validation data\n",
    "X_train_seq, y_train_seq = create_sequences(pd.DataFrame(X_train_scaled), y_train)\n",
    "X_cross_val_seq, y_cross_val_seq = create_sequences(pd.DataFrame(X_cross_val_scaled), y_cross_val)\n",
    "\n",
    "# Initialize the XGBoost regressor model\n",
    "xgb_regressor = XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Fit the model to the training data\n",
    "xgb_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the cross-validation data\n",
    "y_pred_xgb = xgb_regressor.predict(X_cross_val_scaled)\n",
    "\n",
    "# Calculate the RMSE for the XGBoost model\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_cross_val, y_pred_xgb))\n",
    "print(f\"Root Mean Squared Error (RMSE) for XGBoost on Cross-Validation Set: {rmse_xgb:.2f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
