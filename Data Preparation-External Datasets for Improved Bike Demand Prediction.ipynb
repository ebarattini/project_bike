{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5018bcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import BallTree\n",
    "from math import radians\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import BallTree\n",
    "from math import radians\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb847a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_parquet('train.parquet')\n",
    "test_data = pd.read_parquet('test.parquet')\n",
    "final_test_data = pd.read_parquet('final_test.parquet')\n",
    "\n",
    "\n",
    "bike_parking_data = pd.read_excel('stationnement-velo-en-ile-de-france.xlsx')\n",
    "historical_data = pd.read_csv('comptage-velo-donnees-sites-comptage_2020.csv', sep=';')\n",
    "velib_data = pd.read_excel('velib-disponibilite-en-temps-reel.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a41094",
   "metadata": {},
   "source": [
    "### Cleaning Historical Data to Extend Our Datase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "977a7c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1503173 entries, 18 to 2314578\n",
      "Data columns (total 7 columns):\n",
      " #   Column                                    Non-Null Count    Dtype              \n",
      "---  ------                                    --------------    -----              \n",
      " 0   Identifiant du point de comptage          1503173 non-null  int64              \n",
      " 1   Nom du point de comptage                  1479741 non-null  object             \n",
      " 2   Comptage horaire                          1503173 non-null  int64              \n",
      " 3   Date et heure de comptage                 1503173 non-null  datetime64[ns, UTC]\n",
      " 4   Date d'installation du point de comptage  1479741 non-null  object             \n",
      " 5   Lien vers photo du point de comptage      1479741 non-null  object             \n",
      " 6   Coordonnées géographiques                 1479741 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(4)\n",
      "memory usage: 91.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Date et heure de comptage' to datetime with the correct timezone offset handling\n",
    "historical_data['Date et heure de comptage'] = pd.to_datetime(historical_data['Date et heure de comptage'], utc=True)\n",
    "\n",
    "# Define the cutoff date also in UTC for consistency\n",
    "cutoff_date = pd.Timestamp('2020-09-01 01:00:00', tz='UTC')\n",
    "\n",
    "# Filter the data\n",
    "historical_data = historical_data[historical_data['Date et heure de comptage'] < cutoff_date]\n",
    "\n",
    "# Drop columns by name\n",
    "historical_data.drop(\n",
    "    ['Identifiant du point de comptage', \n",
    "     'Date d\\'installation du point de comptage', \n",
    "     'Lien vers photo du point de comptage', \n",
    "     'Coordonnées géographiques'], \n",
    "    axis=1, inplace=True)\n",
    "\n",
    "# Rename the remaining columns\n",
    "historical_data.rename(\n",
    "    columns={\n",
    "        'Nom du point de comptage': 'counter_name',\n",
    "        'Comptage horaire': 'bike_count',\n",
    "        'Date et heure de comptage': 'date'\n",
    "    }, inplace=True)\n",
    "\n",
    "# Create a new column for the logarithmic bike count\n",
    "historical_data['log_bike_count'] = np.log(historical_data['bike_count'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c4cc06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter_name</th>\n",
       "      <th>bike_count</th>\n",
       "      <th>date</th>\n",
       "      <th>log_bike_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2314574</th>\n",
       "      <td>90 Rue De Sèvres</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-08-31 00:00:00+00:00</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314575</th>\n",
       "      <td>90 Rue De Sèvres</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-31 03:00:00+00:00</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314576</th>\n",
       "      <td>90 Rue De Sèvres</td>\n",
       "      <td>10</td>\n",
       "      <td>2020-08-31 05:00:00+00:00</td>\n",
       "      <td>2.397895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314577</th>\n",
       "      <td>90 Rue De Sèvres</td>\n",
       "      <td>40</td>\n",
       "      <td>2020-08-31 12:45:00+00:00</td>\n",
       "      <td>3.713572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314578</th>\n",
       "      <td>90 Rue De Sèvres</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-08-31 23:30:00+00:00</td>\n",
       "      <td>1.791759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             counter_name  bike_count                      date  \\\n",
       "2314574  90 Rue De Sèvres           3 2020-08-31 00:00:00+00:00   \n",
       "2314575  90 Rue De Sèvres           1 2020-08-31 03:00:00+00:00   \n",
       "2314576  90 Rue De Sèvres          10 2020-08-31 05:00:00+00:00   \n",
       "2314577  90 Rue De Sèvres          40 2020-08-31 12:45:00+00:00   \n",
       "2314578  90 Rue De Sèvres           5 2020-08-31 23:30:00+00:00   \n",
       "\n",
       "         log_bike_count  \n",
       "2314574        1.386294  \n",
       "2314575        0.693147  \n",
       "2314576        2.397895  \n",
       "2314577        3.713572  \n",
       "2314578        1.791759  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6b5bd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving historical data to a new csv file\n",
    "historical_data.to_csv(\"historical_data_2020.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986474be",
   "metadata": {},
   "source": [
    "## Adding Velib Availability within Threshold Distance from Counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9efe880c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 date  number_of_Velibs_within_5min_walk\n",
      "0 2020-09-01 02:00:00                                221\n",
      "1 2020-09-01 03:00:00                                221\n",
      "2 2020-09-01 04:00:00                                221\n",
      "3 2020-09-01 15:00:00                                221\n",
      "4 2020-09-01 18:00:00                                221\n"
     ]
    }
   ],
   "source": [
    "# Prepare Velib station data\n",
    "# Assuming 'coordonnee geographique' column contains the lat-lon information\n",
    "velib_data[['latitude', 'longitude']] = velib_data['Coordonnées géographiques'].str.split(',', expand=True).astype(float)\n",
    "velib_lat_lon = np.deg2rad(velib_data[['latitude', 'longitude']].values)\n",
    "\n",
    "# Set threshold for a 5-minute walking distance (approximately 0.42 km)\n",
    "walking_distance_km = 0.42\n",
    "\n",
    "# Function to calculate distances using BallTree\n",
    "def calculate_distances(lat, lon, velib_lat_lon):\n",
    "    tree = BallTree(velib_lat_lon, metric='haversine')\n",
    "    distances, _ = tree.query(np.array([[lat, lon]]), k=len(velib_lat_lon))\n",
    "    return distances[0]\n",
    "\n",
    "# Extract unique latitude and longitude pairs from combined data\n",
    "unique_coords = combined_data[['latitude', 'longitude']].drop_duplicates()\n",
    "\n",
    "# Calculate Velib capacities within walking distance for each unique coordinate\n",
    "velib_capacities = {}\n",
    "for _, row in unique_coords.iterrows():\n",
    "    rad_lat, rad_lon = np.deg2rad([row['latitude'], row['longitude']])\n",
    "    distances = calculate_distances(rad_lat, rad_lon, velib_lat_lon)\n",
    "    velib_capacities[(row['latitude'], row['longitude'])] = velib_data[distances <= walking_distance_km / 6371]['Capacité de la station'].sum()\n",
    "\n",
    "# Map these capacities back to the combined data\n",
    "combined_data['number_of_Velibs_within_5min_walk'] = combined_data.apply(\n",
    "    lambda row: velib_capacities[(row['latitude'], row['longitude'])],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Select only the date column and the new Velib capacity column\n",
    "columns_to_save = ['date', 'number_of_Velibs_within_5min_walk']\n",
    "data_to_save = combined_data[columns_to_save]\n",
    "\n",
    "# Save the selected data to a CSV file\n",
    "data_to_save.to_csv('number_of_velibs_nearby.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the data to save\n",
    "print(data_to_save.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee51bd4d",
   "metadata": {},
   "source": [
    "## Creating a Paris School Holiday Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a2d7aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paris_school_holidays_2020_2022_correct.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the school holiday periods for Paris (Area C) from 2020 to 2022\n",
    "school_holidays = [\n",
    "    {'start': '2020-02-08', 'end': '2020-02-23'},  # Example holiday dates\n",
    "    {'start': '2020-04-04', 'end': '2020-04-20'},\n",
    "    {'start': '2020-07-06', 'end': '2020-09-01'},\n",
    "    {'start': '2020-10-17', 'end': '2020-11-02'},    \n",
    "    {'start': '2020-12-19', 'end': '2021-01-04'},\n",
    "    \n",
    "    {'start': '2021-02-13', 'end': '2021-03-01'},\n",
    "    {'start': '2021-04-17', 'end': '2021-05-03'},  # Example holiday dates\n",
    "    {'start': '2021-07-06', 'end': '2021-09-02'},\n",
    "    {'start': '2021-12-18', 'end': '2022-01-03'},\n",
    "]\n",
    "\n",
    "# Convert the dates to datetime objects\n",
    "for holiday in school_holidays:\n",
    "    holiday['start'] = datetime.strptime(holiday['start'], '%Y-%m-%d')\n",
    "    holiday['end'] = datetime.strptime(holiday['end'], '%Y-%m-%d')\n",
    "\n",
    "# Generate a date range from 2020 to 2022, including every hour\n",
    "start_date = datetime(2020, 1, 1, 0, 0)\n",
    "end_date = datetime(2022, 12, 31, 23, 59)\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(date_range, columns=['datetime'])\n",
    "\n",
    "# Function to check if a date is a school holiday\n",
    "def is_school_holiday(date):\n",
    "    for holiday in school_holidays:\n",
    "        if holiday['start'] <= date <= holiday['end']:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# Apply the function to each date\n",
    "df['is_school_holiday'] = df['datetime'].apply(is_school_holiday)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_file_path = 'paris_school_holidays_2020_2022_correct.csv'\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "csv_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27c4e09",
   "metadata": {},
   "source": [
    "## Extracting and Scaling Velib Availability Data from External Dataset for Bike Demand Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b3ee43",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 54\u001b[0m\n\u001b[0;32m     52\u001b[0m parking_lat \u001b[38;5;241m=\u001b[39m parking[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     53\u001b[0m parking_lon \u001b[38;5;241m=\u001b[39m parking[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 54\u001b[0m distance \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcounter_lat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcounter_lon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparking_lat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparking_lon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Check if the parking is within the biking distance\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m distance \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m biking_distance_threshold:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m# Scale the capacity by distance and add to the total\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 12\u001b[0m, in \u001b[0;36mcalculate_distance\u001b[1;34m(lat1, lon1, lat2, lon2)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_distance\u001b[39m(lat1, lon1, lat2, lon2):\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeodesic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlat1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mlat2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mkilometers\n",
      "File \u001b[1;32m~\\New folder (2)\\lib\\site-packages\\geopy\\distance.py:540\u001b[0m, in \u001b[0;36mgeodesic.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_ellipsoid(kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mellipsoid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWGS-84\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m    539\u001b[0m major, minor, f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mELLIPSOID\n\u001b[1;32m--> 540\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\New folder (2)\\lib\\site-packages\\geopy\\distance.py:276\u001b[0m, in \u001b[0;36mDistance.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m util\u001b[38;5;241m.\u001b[39mpairwise(args):\n\u001b[1;32m--> 276\u001b[0m         kilometers \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeasure\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m kilometers \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m units\u001b[38;5;241m.\u001b[39mkilometers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kilometers \u001b[38;5;241m=\u001b[39m kilometers\n",
      "File \u001b[1;32m~\\New folder (2)\\lib\\site-packages\\geopy\\distance.py:566\u001b[0m, in \u001b[0;36mgeodesic.measure\u001b[1;34m(self, a, b)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeod, Geodesic) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeod\u001b[38;5;241m.\u001b[39ma \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mELLIPSOID[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeod\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mELLIPSOID[\u001b[38;5;241m2\u001b[39m]):\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeod \u001b[38;5;241m=\u001b[39m Geodesic(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mELLIPSOID[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mELLIPSOID[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m--> 566\u001b[0m s12 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlat1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mGeodesic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDISTANCE\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms12\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m s12\n",
      "File \u001b[1;32m~\\New folder (2)\\lib\\site-packages\\geographiclib\\geodesic.py:1030\u001b[0m, in \u001b[0;36mGeodesic.Inverse\u001b[1;34m(self, lat1, lon1, lat2, lon2, outmask)\u001b[0m\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mInverse\u001b[39m(\u001b[38;5;28mself\u001b[39m, lat1, lon1, lat2, lon2,\n\u001b[0;32m   1013\u001b[0m             outmask \u001b[38;5;241m=\u001b[39m GeodesicCapability\u001b[38;5;241m.\u001b[39mSTANDARD):\n\u001b[0;32m   1014\u001b[0m   \u001b[38;5;124;03m\"\"\"Solve the inverse geodesic problem\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m \n\u001b[0;32m   1016\u001b[0m \u001b[38;5;124;03m  :param lat1: latitude of the first point in degrees\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1027\u001b[0m \n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1030\u001b[0m   a12, s12, salp1,calp1, salp2,calp2, m12, M12, M21, S12 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GenInverse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlat1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1032\u001b[0m   outmask \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m Geodesic\u001b[38;5;241m.\u001b[39mOUT_MASK\n\u001b[0;32m   1033\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m outmask \u001b[38;5;241m&\u001b[39m Geodesic\u001b[38;5;241m.\u001b[39mLONG_UNROLL:\n",
      "File \u001b[1;32m~\\New folder (2)\\lib\\site-packages\\geographiclib\\geodesic.py:876\u001b[0m, in \u001b[0;36mGeodesic._GenInverse\u001b[1;34m(self, lat1, lon1, lat2, lon2, outmask)\u001b[0m\n\u001b[0;32m    870\u001b[0m salp1b \u001b[38;5;241m=\u001b[39m Geodesic\u001b[38;5;241m.\u001b[39mtiny_; calp1b \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m numit \u001b[38;5;241m<\u001b[39m Geodesic\u001b[38;5;241m.\u001b[39mmaxit2_:\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# the WGS84 test set: mean = 1.47, sd = 1.25, max = 16\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;66;03m# WGS84 and random input: mean = 2.85, sd = 0.60\u001b[39;00m\n\u001b[0;32m    875\u001b[0m   (v, salp2, calp2, sig12, ssig1, csig1, ssig2, csig2,\n\u001b[1;32m--> 876\u001b[0m    eps, domg12, dv) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Lambda12\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m     \u001b[49m\u001b[43msbet1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbet1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdn1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msbet2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbet2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdn2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m     \u001b[49m\u001b[43msalp1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalp1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslam12\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclam12\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mGeodesic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxit1_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m     \u001b[49m\u001b[43mC1a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC2a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC3a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m   \u001b[38;5;66;03m# Reversed test to allow escape with NaNs\u001b[39;00m\n\u001b[0;32m    881\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m tripb \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mabs\u001b[39m(v) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tripn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m Geodesic\u001b[38;5;241m.\u001b[39mtol0_):\n",
      "File \u001b[1;32m~\\New folder (2)\\lib\\site-packages\\geographiclib\\geodesic.py:690\u001b[0m, in \u001b[0;36mGeodesic._Lambda12\u001b[1;34m(self, sbet1, cbet1, dn1, sbet2, cbet2, dn2, salp1, calp1, slam120, clam120, diffp, C1a, C2a, C3a)\u001b[0m\n\u001b[0;32m    688\u001b[0m     dlam12 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_f1 \u001b[38;5;241m*\u001b[39m dn1 \u001b[38;5;241m/\u001b[39m sbet1\n\u001b[0;32m    689\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 690\u001b[0m     dummy, dlam12, dummy, dummy, dummy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Lengths\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m      \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msig12\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssig1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsig1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdn1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssig2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsig2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdn2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbet1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbet2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mGeodesic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREDUCEDLENGTH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC1a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC2a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    693\u001b[0m     dlam12 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_f1 \u001b[38;5;241m/\u001b[39m (calp2 \u001b[38;5;241m*\u001b[39m cbet2)\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\New folder (2)\\lib\\site-packages\\geographiclib\\geodesic.py:446\u001b[0m, in \u001b[0;36mGeodesic._Lengths\u001b[1;34m(self, eps, sig12, ssig1, csig1, dn1, ssig2, csig2, dn2, cbet1, cbet2, outmask, C1a, C2a)\u001b[0m\n\u001b[0;32m    443\u001b[0m s12b \u001b[38;5;241m=\u001b[39m m12b \u001b[38;5;241m=\u001b[39m m0 \u001b[38;5;241m=\u001b[39m M12 \u001b[38;5;241m=\u001b[39m M21 \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outmask \u001b[38;5;241m&\u001b[39m (Geodesic\u001b[38;5;241m.\u001b[39mDISTANCE \u001b[38;5;241m|\u001b[39m Geodesic\u001b[38;5;241m.\u001b[39mREDUCEDLENGTH \u001b[38;5;241m|\u001b[39m\n\u001b[0;32m    445\u001b[0m               Geodesic\u001b[38;5;241m.\u001b[39mGEODESICSCALE):\n\u001b[1;32m--> 446\u001b[0m   A1 \u001b[38;5;241m=\u001b[39m \u001b[43mGeodesic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_A1m1f\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m   Geodesic\u001b[38;5;241m.\u001b[39m_C1f(eps, C1a)\n\u001b[0;32m    448\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m outmask \u001b[38;5;241m&\u001b[39m (Geodesic\u001b[38;5;241m.\u001b[39mREDUCEDLENGTH \u001b[38;5;241m|\u001b[39m Geodesic\u001b[38;5;241m.\u001b[39mGEODESICSCALE):\n",
      "File \u001b[1;32m~\\New folder (2)\\lib\\site-packages\\geographiclib\\geodesic.py:202\u001b[0m, in \u001b[0;36mGeodesic._A1m1f\u001b[1;34m(eps)\u001b[0m\n\u001b[0;32m    198\u001b[0m coeff \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    199\u001b[0m   \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m256\u001b[39m,\n\u001b[0;32m    200\u001b[0m ]\n\u001b[0;32m    201\u001b[0m m \u001b[38;5;241m=\u001b[39m Geodesic\u001b[38;5;241m.\u001b[39mnA1_\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 202\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[43mMath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolyval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoeff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msq\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m coeff[m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (t \u001b[38;5;241m+\u001b[39m eps) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m eps)\n",
      "File \u001b[1;32m~\\New folder (2)\\lib\\site-packages\\geographiclib\\geomath.py:68\u001b[0m, in \u001b[0;36mMath.polyval\u001b[1;34m(N, p, s, x)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m\"\"\"Evaluate a polynomial.\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m N \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m p[s]) \u001b[38;5;66;03m# make sure the returned value is a float\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mN\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m:\n\u001b[0;32m     69\u001b[0m   N \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m; s \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     70\u001b[0m   y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m*\u001b[39m x \u001b[38;5;241m+\u001b[39m p[s]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Function to extract latitude and longitude from a 'Geo Point' column\n",
    "def extract_lat_lon(geo_point):\n",
    "    lat, lon = map(float, geo_point.split(','))\n",
    "    return lat, lon\n",
    "\n",
    "# Function to calculate the distance between two points\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    return geodesic((lat1, lon1), (lat2, lon2)).kilometers\n",
    "\n",
    "# Function to process the bike parking dataset\n",
    "def process_bike_parking_dataset(bike_parking_data):\n",
    "    # Convert 'date_modif' column to datetime format and remove timezone information\n",
    "    bike_parking_data['date_modif'] = pd.to_datetime(bike_parking_data['date_modif'].astype(str).str[:-6], errors='coerce')\n",
    "\n",
    "    # Define the date range\n",
    "    start_date = datetime(2020, 2, 1)\n",
    "    end_date = datetime(2021, 12, 1)\n",
    "\n",
    "    # Filter the data to include only entries within the specified date range\n",
    "    filtered_df = bike_parking_data[(bike_parking_data['date_modif'] >= start_date) & (bike_parking_data['date_modif'] <= end_date)].copy()\n",
    "\n",
    "    # Extract latitude and longitude\n",
    "    lat_lon = filtered_df['Geo Point'].apply(extract_lat_lon)\n",
    "    filtered_df['latitude'] = lat_lon.apply(lambda x: x[0])\n",
    "    filtered_df['longitude'] = lat_lon.apply(lambda x: x[1])\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "# Process the bike parking dataset\n",
    "processed_bike_parking_df = process_bike_parking_dataset(bike_parking_data)\n",
    "\n",
    "# Define a biking distance threshold (in kilometers)\n",
    "biking_distance_threshold = 2.0\n",
    "\n",
    "# Initialize an empty dictionary to hold the results\n",
    "counter_bike_parking_capacity = {}\n",
    "\n",
    "# Iterate over each counter in test_data\n",
    "for index, counter in test_data.iterrows():\n",
    "    counter_name = counter['counter_name']\n",
    "    counter_lat = counter['latitude']\n",
    "    counter_lon = counter['longitude']\n",
    "\n",
    "    # Calculate the distance to each parking spot and sum the capacities if within biking distance\n",
    "    total_capacity = 0\n",
    "    for _, parking in processed_bike_parking_df.iterrows():\n",
    "        parking_lat = parking['latitude']\n",
    "        parking_lon = parking['longitude']\n",
    "        distance = calculate_distance(counter_lat, counter_lon, parking_lat, parking_lon)\n",
    "\n",
    "        # Check if the parking is within the biking distance\n",
    "        if distance <= biking_distance_threshold:\n",
    "            # Scale the capacity by distance and add to the total\n",
    "            scaled_capacity = parking['capacite'] * (1 - distance / biking_distance_threshold)\n",
    "            total_capacity += scaled_capacity\n",
    "\n",
    "    # Store the result\n",
    "    counter_bike_parking_capacity[counter_name] = total_capacity\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "result_df = pd.DataFrame(list(counter_bike_parking_capacity.items()), columns=['Counter_Name', 'Bike_Parking_Capacity'])\n",
    "\n",
    "csv_file_path = 'counter_bike_parking_capacity.csv'\n",
    "result_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "result_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4f7578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract latitude and longitude from a 'Geo Point' column\n",
    "def extract_lat_lon(geo_point):\n",
    "    return list(map(float, geo_point.split(',')))\n",
    "\n",
    "# Function to calculate the distance between two points\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    return geodesic((lat1, lon1), (lat2, lon2)).kilometers\n",
    "\n",
    "# Function to process the bike parking dataset\n",
    "def process_bike_parking_dataset(bike_parking_data):\n",
    "    # Convert 'date_modif' column to datetime format and remove timezone information\n",
    "    bike_parking_data['date_modif'] = pd.to_datetime(bike_parking_data['date_modif'].astype(str).str[:-6], errors='coerce')\n",
    "\n",
    "    # Define the date range\n",
    "    start_date = datetime(2020, 2, 1)\n",
    "    end_date = datetime(2021, 12, 1)\n",
    "\n",
    "    # Filter the data to include only entries within the specified date range\n",
    "    filtered_df = bike_parking_data[(bike_parking_data['date_modif'] >= start_date) & (bike_parking_data['date_modif'] <= end_date)]\n",
    "\n",
    "    # Extract latitude and longitude\n",
    "    filtered_df[['latitude', 'longitude']] = pd.DataFrame(filtered_df['Geo Point'].apply(extract_lat_lon).tolist(), index=filtered_df.index)\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Load the smaller dataset\n",
    "final_test_data = pd.read_parquet('final_test.parquet')\n",
    "\n",
    "# Process the bike parking dataset\n",
    "processed_bike_parking_df = process_bike_parking_dataset(bike_parking_data)\n",
    "\n",
    "# Define a biking distance threshold (in kilometers)\n",
    "biking_distance_threshold = 2.0\n",
    "\n",
    "# Vectorized distance calculation\n",
    "def calculate_scaled_capacity(row, bike_parking_df, threshold):\n",
    "    distances = bike_parking_df.apply(lambda x: calculate_distance(row['latitude'], row['longitude'], x['latitude'], x['longitude']), axis=1)\n",
    "    close_parkings = bike_parking_df[distances <= threshold]\n",
    "    scaled_capacities = close_parkings['capacite'] * (1 - distances[distances <= threshold] / threshold)\n",
    "    return scaled_capacities.sum()\n",
    "\n",
    "# Apply the calculation to each row in the final_test_data\n",
    "result_df = final_test_data.copy()\n",
    "result_df['Bike_Parking_Capacity'] = result_df.apply(calculate_scaled_capacity, args=(processed_bike_parking_df, biking_distance_threshold), axis=1)\n",
    "\n",
    "# Save the results\n",
    "csv_file_path = 'counter_bike_parking_capacity_optimized.csv'\n",
    "result_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "result_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
